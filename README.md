# oar-autocomplete
Autocomplete functionality for the NIST Science Data Portal.

Server functionality, as well as initial setup, is included in `server.py`, while `autocomplete.py` does the actual processing. This program utilizes a multiprocessing pool to leverage multiple CPU cores, and attempts to find matching search terms in real-time, as little as 100ms from the user typing a character to them seeing suggested results. Both files are platform agnostic; they have been tested to run on Ubuntu in a virtual machine, Ubuntu under WSL, and Windows, and should run on any Unix based system including Mac OS.

*Note that this repository was made with Python 3 in mind, and has only been tested with Python 3.6, 3.8, and 3.9.5 Windows Store Version. None of this code is tested to work with Python 2.7, which reached EOL in 2020.*

# Main Components

`server.py` - Handles reading data from a CSV file, creation of an HTTP server to respond to search queries, and creation of a multiprocessing pool. Reachable from localhost:8000.

`autocomplete.py` - Handles the processing to find closest matches between the query string and a term or phrase in the CSV file, generated by parmenides.

# Optional Components

`simple_http.py` - Serves a static directory (from the user's pwd) as a website, reachable from localhost:8080. **This service is to be used for testing purposes only**. It makes only basic checks against attacks, and is not encrypted.

# Prerequisites

|[pandas](https://pypi.org/project/pandas/) | `pip install pandas`|
| :---: | :--- |
|[parmenides](https://gitlab.nist.gov/gitlab/jacob.collard/parmenides) | `git clone https://gitlab.nist.gov/gitlab/jacob.collard/parmenides.git; pip install -e parmenides`
|[spacy](https://pypi.org/project/spacy/) | `pip install spacy; python -m spacy download en_core_web_sm` |

# Generating a dataset

Parmenides is required for generating the dataset seen in `parmenides_results.csv`. The data itself comes from the [NIST SDP web API](https://data.nist.gov/rmm/records), the output of which can be seen in `nerdm.json`. After extracting the titles, themes, keywords, descriptions, and topics of each document in the nerdm JSON, they can be parsed by Parmenides. The JSONSource extension is responsible for parsing the JSON file inside of Parmenides.

`python -m parmenides -s settings.py -o parmenides_results.csv nerdm.json ResultData`

After this point, the Python server can be run and accessed from `localhost:8000/<search_terms>`

To summarize:

`curl -X GET "https://data.nist.gov/rmm/records" -H "accept: application/json" > nerdm.json`

`python -m parmenides -s settings.py -o parmenides_results.csv nerdm.json ResultData`

`python server.py`
